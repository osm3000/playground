# Algorithms

* Implement a basic Neural Network agent + EA algorithm
  * An agent with FF neural Network, and another with RNN
* Implement NEAT/HyperNEAT algorithms with their relevant agents.
* Add a tree search (MCTS) to the agent.

# Reward shaping
Summary: The current reward function is so steep. Thus, it will make more sense to find small rewards (in short, reward engineering). This is quite tricky, but we will see.

# Logistics
* Get familiar with the Docker submission procedure.

# Research part
* Memory (internal/external/shared/discrete/continuous)

# Open Questions
* Should I scale the features given to the neural network or not?
* Can we do a MinMax approach to the problem?
* If the agent have memory, do we need a tree search?
